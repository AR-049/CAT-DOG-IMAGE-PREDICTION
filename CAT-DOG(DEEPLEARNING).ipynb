{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=r'C:\\Users\\Anjali\\Desktop\\cats_and_dog_small\\train'\n",
    "validation_dir=r'C:\\Users\\Anjali\\Desktop\\cats_and_dog_small\\validation'\n",
    "test_dir=r'C:\\Users\\Anjali\\Desktop\\cats_and_dog_small\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,target_size=(150,150),batch_size=32,class_mode='binary'\n",
    ")\n",
    "validation_generator=test_datagen.flow_from_directory(\n",
    "    validation_dir,target_size=(150,150),batch_size=32,class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "conv_base=VGG16(weights='imagenet',\n",
    "               include_top=False,\n",
    "               input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "model=models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb=keras.callbacks.ModelCheckpoint(\"CNN_Project_Model-{epoch:02d}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-a41c76fb5418>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      " 63/100 [=================>............] - ETA: 7:11 - loss: 0.5058 - acc: 0.7385WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3000 batches). You may need to use the repeat() function when building your dataset.\n",
      " 63/100 [=================>............] - ETA: 7:35 - loss: 0.5057 - acc: 0.7385"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=100,\n",
    "                            epochs=30,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=50,\n",
    "                            callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAUvklEQVR4nO3df5BddXnH8fdDSIgYxIQfAbPRBI0zDYEQ2CCObVgKhgRHgj9ayUwxoJA/Wuy0VqY4IFZwqpJxYBhSZadlBGcw4K82rUEqlmvQARvERAgQiKGUBVogCdQFAiQ8/WOvzGVzw97s3rvf3Lvv18ydveec7zn3uc8EPnvOPfu9kZlIkqRy9itdgCRJY51hLElSYYaxJEmFGcaSJBVmGEuSVJhhLElSYUOGcURcHxFPR8T9e9geEXFNRGyOiN9ExPHNL1OSpM7VyJnxt4BFb7J9MTCr+lgOfGPkZUmSNHYMGcaZuRbY9iZDlgA35oC7gbdHxJHNKlCSpE7XjM+MpwGP1yz3VddJkqQG7N+EY0SddXXn2IyI5QxcyuYtb3nLCdOnT2/Cy4+e1157jf328563VrLHrWePR4d9br126/HDDz/8bGYeVm9bM8K4D6hN1S7gyXoDM7MX6AXo7u7Oe+65pwkvP3oqlQo9PT2ly+ho9rj17PHosM+t1249jojH9rStGb9SrAY+Wb2r+iTg+cx8qgnHlSRpTBjyzDgivgP0AIdGRB/wRWA8QGZ+E1gDnAFsBl4EzmtVsZIkdaIhwzgzlw6xPYG/aFpFkiSNMc34zFiSpL326quv0tfXx44dO4a1/8EHH8yDDz7Y5KpGbuLEiXR1dTF+/PiG9zGMJUlF9PX1cdBBBzFjxgwi6v1hzpv73e9+x0EHHdSCyoYvM9m6dSt9fX3MnDmz4f3a555wSVJH2bFjB4cccsiwgnhfFREccsghe322bxhLkorppCD+veG8J8NYkjRmTZo0qXQJgGEsSVJxhrEkaczLTC666CLmzJnDMcccw8033wzAU089xYIFCzjuuOOYM2cOd955J7t27eLcc899fexVV1014tf3bmpJ0pj3gx/8gPXr17NhwwaeffZZ5s+fz4IFC7jppps4/fTTueSSS9i1axcvvvgi69ev54knnuD+++8H4Lnnnhvx6xvGkqTivvSvG3ngyf/bq3127drFuHHj9rh99jvexhc/fHRDx/r5z3/O0qVLGTduHFOnTuXkk09m3bp1zJ8/n0996lO8+uqrnHXWWRx33HEcddRRbNmyhc985jN86EMfYuHChXtVdz1eppYkjXkDk0nubsGCBaxdu5Zp06ZxzjnncOONNzJ58mQ2bNhAT08PK1eu5Pzzzx/x63tmLEkqrtEz2FrNnPRjwYIFXHfddSxbtoxt27axdu1aVqxYwWOPPca0adO44IILeOGFF7j33ns544wzmDBhAh/72Md497vfzbnnnjvi1zeMJUlj3kc+8hHuuusu5s6dS0Rw5ZVXcsQRR3DDDTewYsUKxo8fz6RJk7jxxht54oknOO+883jttdcA+MpXvjLi1zeMJUljVn9/PzAwUceKFStYsWLFG7YvW7aMZcuW7bbfvffe29Q6/MxYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkjSmnXXWWZxwwgkcffTR9Pb2AvDjH/+Y448/nrlz53LqqacCAxOEnHfeeRxzzDEce+yxfP/7329aDc7AJUka066//nqmTJnCSy+9xPz581myZAkXXHABa9euZebMmWzbtg2AK664goMPPpj77rsPgO3btzetBsNYklTerRfD/9y3V7u8ZddOGPcmMXbEMbD4q0Me55prruGHP/whAI8//ji9vb0sWLCAmTNnAjBlyhQAbr/9dlatWvX6fpMnT96ret+Ml6klSWNWpVLh9ttv56677mLDhg3Mmzfv9S+LGCwz665vBs+MJUnlNXAGO9hLTfgKxeeff57Jkydz4IEH8tBDD3H33Xfz8ssv87Of/YxHH3309cvUU6ZMYeHChVx77bVcffXVwMBl6madHXtmLEkasxYtWsTOnTs59thj+cIXvsBJJ53EYYcdRm9vLx/96EeZO3cun/jEJwC49NJL2b59O3PmzGHu3LnccccdTavDM2NJ0ph1wAEHcOutt9bdtnjx4jcsT5o0iRtuuKEldXhmLElSYYaxJEmFGcaSJBVmGEuSisnM0iU03XDek2EsSSpi4sSJbN26taMCOTPZunUrEydO3Kv9vJtaklREV1cXfX19PPPMM8Paf8eOHXsdeqNh4sSJdHV17dU+hrEkqYjx48e/PuXkcFQqFebNm9fEisrxMrUkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUWENhHBGLImJTRGyOiIvrbH9nRNwREb+OiN9ExBnNL1WSpM40ZBhHxDhgJbAYmA0sjYjZg4ZdCtySmfOAs4F/aHahkiR1qkbOjE8ENmfmlsx8BVgFLBk0JoG3VZ8fDDzZvBIlSepsMdSXOkfEx4FFmXl+dfkc4H2ZeWHNmCOBfwcmA28FTsvMX9U51nJgOcDUqVNPWLVqVbPex6jo7+9n0qRJpcvoaPa49ezx6LDPrdduPT7llFN+lZnd9bY18n3GUWfd4ARfCnwrM78eEe8Hvh0RczLztTfslNkL9AJ0d3dnT09PAy+/76hUKrRbze3GHreePR4d9rn1OqnHjVym7gOm1yx3sftl6E8DtwBk5l3ARODQZhQoSVKnaySM1wGzImJmRExg4Aat1YPG/DdwKkBE/AEDYfxMMwuVJKlTDRnGmbkTuBC4DXiQgbumN0bE5RFxZnXY3wAXRMQG4DvAuTnUh9GSJAlo7DNjMnMNsGbQustqnj8AfKC5pUmSNDY4A5ckSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYUZxpIkFWYYS5JUmGEsSVJhhrEkSYU1FMYRsSgiNkXE5oi4eA9j/jQiHoiIjRFxU3PLlCSpc+0/1ICIGAesBD4I9AHrImJ1Zj5QM2YW8HngA5m5PSIOb1XBkiR1mkbOjE8ENmfmlsx8BVgFLBk05gJgZWZuB8jMp5tbpiRJnauRMJ4GPF6z3FddV+u9wHsj4hcRcXdELGpWgZIkdbohL1MDUWdd1jnOLKAH6ALujIg5mfncGw4UsRxYDjB16lQqlcre1ltUf39/29Xcbuxx69nj0WGfW6+TetxIGPcB02uWu4An64y5OzNfBR6NiE0MhPO62kGZ2Qv0AnR3d2dPT88wyy6jUqnQbjW3G3vcevZ4dNjn1uukHjdymXodMCsiZkbEBOBsYPWgMf8MnAIQEYcycNl6SzMLlSSpUw0Zxpm5E7gQuA14ELglMzdGxOURcWZ12G3A1oh4ALgDuCgzt7aqaEmSOkkjl6nJzDXAmkHrLqt5nsBnqw9JkrQXnIFLkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCDGNJkgozjCVJKswwliSpMMNYkqTCGgrjiFgUEZsiYnNEXPwm4z4eERkR3c0rUZKkzjZkGEfEOGAlsBiYDSyNiNl1xh0E/CXwy2YXKUlSJ2vkzPhEYHNmbsnMV4BVwJI6464ArgR2NLE+SZI6XiNhPA14vGa5r7rudRExD5iemf/WxNokSRoT9m9gTNRZl69vjNgPuAo4d8gDRSwHlgNMnTqVSqXSUJH7iv7+/rarud3Y49azx6PDPrdeJ/W4kTDuA6bXLHcBT9YsHwTMASoRAXAEsDoizszMe2oPlJm9QC9Ad3d39vT0DL/yAiqVCu1Wc7uxx61nj0eHfW69TupxI5ep1wGzImJmREwAzgZW/35jZj6fmYdm5ozMnAHcDewWxJIkqb4hwzgzdwIXArcBDwK3ZObGiLg8Is5sdYGSJHW6Ri5Tk5lrgDWD1l22h7E9Iy9LkqSxwxm4JEkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKmwhsI4IhZFxKaI2BwRF9fZ/tmIeCAifhMRP42IdzW/VEmSOtOQYRwR44CVwGJgNrA0ImYPGvZroDszjwW+B1zZ7EIlSepUjZwZnwhszswtmfkKsApYUjsgM+/IzBeri3cDXc0tU5KkzrV/A2OmAY/XLPcB73uT8Z8Gbq23ISKWA8sBpk6dSqVSaazKfUR/f3/b1dxu7HHr2ePRYZ9br5N63EgYR511WXdgxJ8B3cDJ9bZnZi/QC9Dd3Z09PT2NVbmPqFQqtFvN7cYet549Hh32ufU6qceNhHEfML1muQt4cvCgiDgNuAQ4OTNfbk55kiR1vkY+M14HzIqImRExATgbWF07ICLmAdcBZ2bm080vU5KkzjVkGGfmTuBC4DbgQeCWzNwYEZdHxJnVYSuAScB3I2J9RKzew+EkSdIgjVymJjPXAGsGrbus5vlpTa5LkqQxwxm4JEkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqrKEwjohFEbEpIjZHxMV1th8QETdXt/8yImY0u1BJkjrVkGEcEeOAlcBiYDawNCJmDxr2aWB7Zr4HuAr4WrMLlSSpUzVyZnwisDkzt2TmK8AqYMmgMUuAG6rPvwecGhHRvDIlSepcjYTxNODxmuW+6rq6YzJzJ/A8cEgzCpQkqdPt38CYeme4OYwxRMRyYHl1sT8iNjXw+vuSQ4FnSxfR4exx69nj0WGfW6/devyuPW1oJIz7gOk1y13Ak3sY0xcR+wMHA9sGHygze4HeBl5znxQR92Rmd+k6Opk9bj17PDrsc+t1Uo8buUy9DpgVETMjYgJwNrB60JjVwLLq848D/5GZu50ZS5Kk3Q15ZpyZOyPiQuA2YBxwfWZujIjLgXsyczXwT8C3I2IzA2fEZ7eyaEmSOkkjl6nJzDXAmkHrLqt5vgP4k+aWtk9q20vsbcQet549Hh32ufU6psfh1WRJkspyOkxJkgozjAeJiCkR8ZOIeKT6c/Iexi2rjnkkIpbV2b46Iu5vfcXtZyQ9jogDI+JHEfFQRGyMiK+ObvX7tpFMXRsRn6+u3xQRp49m3e1kuD2OiA9GxK8i4r7qzz8e7drbxUinYI6Id0ZEf0R8brRqHrHM9FHzAK4ELq4+vxj4Wp0xU4At1Z+Tq88n12z/KHATcH/p97MvPkbSY+BA4JTqmAnAncDi0u9pX3gwcIPlb4Gjqr3ZAMweNObPgW9Wn58N3Fx9Prs6/gBgZvU440q/p33tMcIezwPeUX0+B3ii9PvZFx8j6XHN9u8D3wU+V/r9NPrwzHh3tVN73gCcVWfM6cBPMnNbZm4HfgIsAoiIScBngS+PQq3tatg9zswXM/MOgByYnvVeBv72XSObunYJsCozX87MR4HN1ePpjYbd48z8dWb+fo6GjcDEiDhgVKpuLyOagjkizmLgl/eNo1RvUxjGu5uamU8BVH8eXmfMm00RegXwdeDFVhbZ5kbaYwAi4u3Ah4GftqjOdjOSqWsb2VfNmx74Y8CvM/PlFtXZzobd44h4K/C3wJdGoc6mauhPmzpNRNwOHFFn0yWNHqLOuoyI44D3ZOZfj/WvkWxVj2uOvz/wHeCazNyy9xV2pJFMXdvQlLYa+fTAEXE0A99st7CJdXWSkfT4S8BVmdnfbt9VNCbDODNP29O2iPjfiDgyM5+KiCOBp+sM6wN6apa7gArwfuCEiPgvBnp7eERUMrOHMaaFPf69XuCRzLy6CeV2ipFMXdvIvhrh9MAR0QX8EPhkZv629eW2pZH0+H3AxyPiSuDtwGsRsSMzr2192SPjZerd1U7tuQz4lzpjbgMWRsTk6p3AC4HbMvMbmfmOzJwB/CHw8FgM4gYMu8cAEfFlBv7j+6tRqLWdjGTq2tXA2dW7VGcCs4D/HKW628mwe1z9WOVHwOcz8xejVnH7GXaPM/OPMnNG9f/BVwN/3w5BDHg39eAHA5/t/BR4pPpzSnV9N/CPNeM+xcBNLpuB8+ocZwbeTd30HjPwW3ICDwLrq4/zS7+nfeUBnAE8zMDdqJdU110OnFl9PpGBu0w3MxC2R9Xse0l1v014h3rTewxcCrxQ8+92PXB46fezLz5G8u+45hh/RxvdTe0MXJIkFeZlakmSCjOMJUkqzDCWJKkww1iSpMIMY0mSCjOMJUkqzDCWJKkww1iSpML+H884czbLEovUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df=pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator=test_datagen.flow_from_directory(test_dir,target_size=(150,150),batch_size=20,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-0a887b631832>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2115485654771328, 0.919]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator,steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
